{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spotify Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "\n",
    "spotify = pd.read_csv('spotify.csv')\n",
    "print(spotify.shape)\n",
    "spotify.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should check if there are any duplicates in our song list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated = spotify[spotify['track_id'].duplicated(keep = False)]\n",
    "duplicated.groupby('track_id')['track_id'].count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see if these songs have any different attribute than their id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_counts = spotify.track_id.value_counts()\n",
    "repeated_tracks = track_counts[track_counts>1]\n",
    "for track in repeated_tracks.index[:3]:\n",
    "  display(spotify[spotify.track_id==track].head())\n",
    "  print('_'*150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that only 'track_genre' is different for these repeated rows..\n",
    "But let us check some other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['artists', 'album_name', 'track_name', 'popularity', 'duration_ms', 'explicit', 'danceability', 'energy','key',\n",
    "                    'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness','valence', 'tempo', 'time_signature']\n",
    "for track in repeated_tracks.index:\n",
    "  temp_df = spotify.loc[spotify.track_id==track,columns_to_check]\n",
    "  try:\n",
    "    assert temp_df.duplicated(keep=False).all(), 'There is/are differences in the repeated rows other than \"track_genre\" column'\n",
    "  except AssertionError as e:\n",
    "    print(f\"An assertion error occurred for {track=}: {e}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have another different column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a very small difference in the 'popularity' column which we can accept if we exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spotify[spotify['track_id'].duplicated(keep = 'first') == False]\n",
    "df.dropna(inplace=True)\n",
    "df = df.set_index('track_id')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most likely 'track_genre' will have some effect so we should use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = spotify.groupby('track_genre')['danceability'].mean()\n",
    "grouped.sort_values(ascending = False)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,3), dpi = 100)\n",
    "sns.barplot(x = grouped.sort_values(ascending = False)[0:].index, y = grouped.sort_values(ascending = False)[0:].values)\n",
    "plt.xlabel('Track genre')\n",
    "plt.ylabel('Danceability')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title('Most Danceable Genres')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like we were right so let's convert these to codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_genre = df.track_genre.astype('category').cat.codes\n",
    "track_genre.name = 'track_genre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_select = ['popularity','duration_ms', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
    "                     'instrumentalness', 'liveness','valence', 'tempo', 'time_signature', 'danceability']\n",
    "df_selected = pd.concat([track_genre, df[columns_to_select]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us see if we have some missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_selected.corr()\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(corr_matrix, mask=np.triu(corr_matrix), annot=True, fmt='.2f');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also make a plot of variables sorted according to 'abs of correlation' with 'danceability'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = pd.DataFrame(corr_matrix.danceability[:-1])\n",
    "corr_data.columns = ['Corr']\n",
    "corr_data['Abs_Corr'] = corr_data.Corr.abs()\n",
    "\n",
    "corr_data['Color'] = ['b' if x >= 0 else 'r' for x in corr_data.Corr]\n",
    "\n",
    "corr_data_sorted = corr_data.sort_values(by='Abs_Corr')\n",
    "corr_data_sorted.Abs_Corr.plot(kind='barh', color=corr_data.Color, figsize=(10, 5))\n",
    "plt.xlabel('Absolute Value of Correlation (Blue: Positive corr., Red: Negative corr.)'); plt.grid()\n",
    "plt.ylabel('Variable Name'); plt.title('Variables Sorted by \"Absolute Value of Correlation\" with Danceability');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'valence', 'loudness', 'time_signature', 'instrumentalness', and 'acousticness' are very important features (corr-coeff > 0.15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df_selected_scaled = scaler.fit_transform(df_selected)\n",
    "df_selected = pd.DataFrame(df_selected_scaled, columns=df_selected.columns)\n",
    "df_selected"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and train a fully connected neural network to predict 'danceability'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_selected.iloc[:,:-1] \n",
    "y = df_selected['danceability'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(14,)),  \n",
    "    tf.keras.layers.Dense(128, activation='relu'), \n",
    "    tf.keras.layers.Dense(64, activation='relu'),  \n",
    "    tf.keras.layers.Dense(32, activation='relu'),  \n",
    "    tf.keras.layers.Dense(1) \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=10, verbose=0, validation_data=(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate the model and try to understand what is going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "mse_train_lr = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test_lr = mean_squared_error(y_test, y_pred_test)\n",
    "print(f\"Mean Squared Error for Train Data: {mse_train_lr:.4g}\")\n",
    "print(f\"Mean Squared Error for Test Data:  {mse_test_lr:.4g}\")\n",
    "\n",
    "# Calculate the \"R2 Score\" of the model on train and test data..\n",
    "# The \"R2 Score\", also known as the coefficient of determination, is a measure of how well the model's predictions match the actual data.\n",
    "# An \"R2 Score\" of 1 indicates perfect predictions, while an \"R2 Score\" of 0 indicates that the model is no better than a model that\n",
    "# would simply predict the mean of the target variable for all observations.\n",
    "r2_train_lr = r2_score(y_train, y_pred_train)\n",
    "r2_test_lr = r2_score(y_test, y_pred_test)\n",
    "print(f\"R2 Score for Train Data: {r2_train_lr:.4g}\")\n",
    "print(f\"R2 Score for Test Data:  {r2_test_lr:.4g}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around 0.6 R^2 is not too bad but it's still not good enough. Let's see some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_train = y_train - tf.squeeze(y_pred_train, axis=1)\n",
    "residuals_test = y_test - tf.squeeze(y_pred_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].hist(residuals_train, bins=20, edgecolor='black')\n",
    "axs[0].set_title('Histogram of Training Residuals'); axs[0].set_xlabel('Residual'); axs[0].set_ylabel('Frequency')\n",
    "axs[1].hist(residuals_test, bins=20, edgecolor='black')\n",
    "axs[1].set_title('Histogram of Test Residuals'); axs[1].set_xlabel('Residual'); axs[1].set_ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the residuals are normally distributed which means that our fully connected neural network is an acceptable choice to explain the variability in the output/target variable.\n",
    "Now let us see a scatter plot of the prediction and the actual value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].scatter(y_train, y_pred_train, c='blue', marker='.', alpha=.1)\n",
    "axs[0].set_title('Scatter Plot for Training Data'); axs[0].set_xlabel('Actual'); axs[0].set_ylabel('Predicted')\n",
    "axs[1].scatter(y_test, y_pred_test, c='blue', marker='.', alpha=.1)\n",
    "axs[1].set_title('Scatter Plot for Training Data'); axs[1].set_xlabel('Actual'); axs[1].set_ylabel('Predicted');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try another technique to predict 'danceability'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = rf_regressor.predict(X_train)\n",
    "y_pred_test = rf_regressor.predict(X_test)\n",
    "\n",
    "mse_train_rf = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test_rf = mean_squared_error(y_test, y_pred_test)\n",
    "print(f\"Mean Squared Error on Train Data: {mse_train_rf:.4g}\")\n",
    "print(f\"Mean Squared Error on Test Data:  {mse_test_rf:.4g}\")\n",
    "\n",
    "# Calculate the \"R2 Score\" of the model on train and test data..\n",
    "r2_train_rf = r2_score(y_train, y_pred_train)\n",
    "r2_test_rf = r2_score(y_test, y_pred_test)\n",
    "print(f\"R2 Score for Train Data: {r2_train_rf:.4g}\")\n",
    "print(f\"R2 Score for Test Data:  {r2_test_rf:.4g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like Random Forest performs better but we should summarize how much better!\n",
    "It is important to notice that on the test data the performance of the model is way worse than on the train data. It is coming from the nature of the decision trees but it is still better than the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_comparison_table = pd.DataFrame(index=['Linear Regressor','RandomForest Regressor'])\n",
    "performance_comparison_table['MSE (Train)'] = [mse_train_lr,mse_train_rf]\n",
    "performance_comparison_table['MSE (Test)'] = [mse_test_lr,mse_test_rf]\n",
    "performance_comparison_table['R2 (Train)'] = [r2_train_lr,r2_train_rf]\n",
    "performance_comparison_table['R2 (Test)'] = [r2_test_lr,r2_test_rf]\n",
    "performance_comparison_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To close this study we should see how well our model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_all = rf_regressor.predict(X)\n",
    "_, axs = plt.subplots(2, 1, figsize=(10, 10))\n",
    "axs[0].scatter(y, y_pred_all, c='blue', marker='.', alpha=.1); axs[0].set_aspect('equal')\n",
    "axs[0].set_title('Scatter Plot of Actual and Predicted Danceability'); axs[0].set_xlabel('Actual'); axs[0].set_ylabel('Predicted')\n",
    "axs[1].plot(np.column_stack([y, y_pred_all]), alpha=.5); axs[1].legend(['Actual','Predicted'])\n",
    "axs[1].set_title('Line plots of Actual and Predicted Danceability'); axs[1].set_xlabel('Index'); axs[1].set_ylabel('Value');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a14426722b25adc768cfea782f621c901ff82b6a9f568e699338819587caab5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
