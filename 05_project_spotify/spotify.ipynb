{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spotify Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "\n",
    "spotify = pd.read_csv('spotify.csv')\n",
    "print(spotify.shape)\n",
    "spotify.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should check if there are any duplicates in our song list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated = spotify[spotify['track_id'].duplicated(keep = False)]\n",
    "duplicated.groupby('track_id')['track_id'].count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see if these songs have any different attribute than their id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_counts = spotify.track_id.value_counts()\n",
    "repeated_tracks = track_counts[track_counts>1]\n",
    "for track in repeated_tracks.index[:3]:\n",
    "  display(spotify[spotify.track_id==track].head())\n",
    "  print('_'*150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that only 'track_genre' is different for these repeated rows..\n",
    "But let us check some other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['artists', 'album_name', 'track_name', 'popularity', 'duration_ms', 'explicit', 'danceability', 'energy','key',\n",
    "                    'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness','valence', 'tempo', 'time_signature']\n",
    "for track in repeated_tracks.index:\n",
    "  temp_df = spotify.loc[spotify.track_id==track,columns_to_check]\n",
    "  try:\n",
    "    assert temp_df.duplicated(keep=False).all(), 'There is/are differences in the repeated rows other than \"track_genre\" column'\n",
    "  except AssertionError as e:\n",
    "    print(f\"An assertion error occurred for {track=}: {e}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have another different column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a very small difference in the 'popularity' column which we can accept if we exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spotify[spotify['track_id'].duplicated(keep = 'first') == False]\n",
    "df.dropna(inplace=True)\n",
    "df = df.set_index('track_id')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most likely 'track_genre' will have some effect so we should use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = spotify.groupby('track_genre')['danceability'].mean()\n",
    "grouped.sort_values(ascending = False)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,3), dpi = 100)\n",
    "sns.barplot(x = grouped.sort_values(ascending = False)[0:].index, y = grouped.sort_values(ascending = False)[0:].values)\n",
    "plt.xlabel('Track genre')\n",
    "plt.ylabel('Danceability')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title('Most Danceable Genres')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like we were right so let's convert these to codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_genre = df.track_genre.astype('category').cat.codes\n",
    "track_genre.name = 'track_genre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_select = ['popularity','duration_ms', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
    "                     'instrumentalness', 'liveness','valence', 'tempo', 'time_signature', 'danceability']\n",
    "df_selected = pd.concat([track_genre, df[columns_to_select]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us see if we have some missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_selected.corr()\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(corr_matrix, mask=np.triu(corr_matrix), annot=True, fmt='.2f');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also make a plot of variables sorted according to 'abs of correlation' with 'danceability'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = pd.DataFrame(corr_matrix.danceability[:-1])\n",
    "corr_data.columns = ['Corr']\n",
    "corr_data['Abs_Corr'] = corr_data.Corr.abs()\n",
    "\n",
    "corr_data['Color'] = ['b' if x >= 0 else 'r' for x in corr_data.Corr]\n",
    "\n",
    "corr_data_sorted = corr_data.sort_values(by='Abs_Corr')\n",
    "corr_data_sorted.Abs_Corr.plot(kind='barh', color=corr_data.Color, figsize=(10, 5))\n",
    "plt.xlabel('Absolute Value of Correlation (Blue: Positive corr., Red: Negative corr.)'); plt.grid()\n",
    "plt.ylabel('Variable Name'); plt.title('Variables Sorted by \"Absolute Value of Correlation\" with Danceability');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'valence', 'loudness', 'time_signature', 'instrumentalness', and 'acousticness' are very important features (corr-coeff > 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(exclude='object')\n",
    "data = numeric_df.values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "scaled_numeric_df = pd.DataFrame(data_scaled, columns=numeric_df.columns)\n",
    "scaled_numeric_df.head()\n",
    "\n",
    "dataplot = sns.heatmap(scaled_numeric_df.corr(), cmap=\"YlGnBu\", annot=True)\n",
    "sns.set(rc={'figure.figsize':(17,17)})\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_selected_scaled = scaler.fit_transform(df_selected)\n",
    "df_selected = pd.DataFrame(df_selected_scaled, columns=df_selected.columns)\n",
    "df_selected"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and train a fully connected neural network to predict 'danceability'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_selected.iloc[:,:-1] \n",
    "y = df_selected['danceability'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(14,)),  \n",
    "    tf.keras.layers.Dense(128, activation='relu'), \n",
    "    tf.keras.layers.Dense(64, activation='relu'),  \n",
    "    tf.keras.layers.Dense(32, activation='relu'),  \n",
    "    tf.keras.layers.Dense(1) \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=10, verbose=0, validation_data=(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate the model and try to understand what is going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "mse_train_lr = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test_lr = mean_squared_error(y_test, y_pred_test)\n",
    "print(f\"Mean Squared Error for Train Data: {mse_train_lr:.4g}\")\n",
    "print(f\"Mean Squared Error for Test Data:  {mse_test_lr:.4g}\")\n",
    "\n",
    "# Calculate the \"R2 Score\" of the model on train and test data..\n",
    "# The \"R2 Score\", also known as the coefficient of determination, is a measure of how well the model's predictions match the actual data.\n",
    "# An \"R2 Score\" of 1 indicates perfect predictions, while an \"R2 Score\" of 0 indicates that the model is no better than a model that\n",
    "# would simply predict the mean of the target variable for all observations.\n",
    "r2_train_lr = r2_score(y_train, y_pred_train)\n",
    "r2_test_lr = r2_score(y_test, y_pred_test)\n",
    "print(f\"R2 Score for Train Data: {r2_train_lr:.4g}\")\n",
    "print(f\"R2 Score for Test Data:  {r2_test_lr:.4g}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around 0.6 R^2 is not too bad but it's still not good enough. Let's see some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#residuals_train = y_train - y_pred_train\n",
    "#residuals_test = y_test - y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].hist(residuals_train, bins=20, edgecolor='black')\n",
    "axs[0].set_title('Histogram of Training Residuals'); axs[0].set_xlabel('Residual'); axs[0].set_ylabel('Frequency')\n",
    "axs[1].hist(residuals_test, bins=20, edgecolor='black')\n",
    "axs[1].set_title('Histogram of Test Residuals'); axs[1].set_xlabel('Residual'); axs[1].set_ylabel('Frequency');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5  #top feature num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_numeric_df_wo_d = scaled_numeric_df.drop(columns=['danceability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaled_numeric_df_wo_d\n",
    "y = scaled_numeric_df['danceability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_regressor = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "feature_importances = rf_regressor.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "top_features = feature_importance_df.head(N)\n",
    "\n",
    "print(f\"Top {N} Important Features:\")\n",
    "print(top_features)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_features['Feature'], top_features['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top Features for Predicting Target (Random Forest)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_features = ['valence', 'loudness', 'acousticness', 'tempo']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = scaled_numeric_df[used_features + ['danceability']].sample(n = 100, random_state=2)\n",
    "X_predict = to_predict[used_features].values\n",
    "y_result = []\n",
    "for i, row in enumerate(X_predict):\n",
    "    tmp = model.predict(row.reshape(1, 4), verbose=0)\n",
    "    y_result.append([tmp, to_predict.iloc[i].at['danceability']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_array = np.array(y_result)\n",
    "ind = np.argsort(-acc_array[:,0]) # Reverse order\n",
    "sorted = acc_array[ind]\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(sorted[:,0] , label = 'Real values')\n",
    "plt.plot(sorted[:,1], label =  'Prediction')\n",
    "plt.title('Test Accuracy')\n",
    "plt.ylabel('Values')\n",
    "plt.xlabel('Datapoints')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decision tree regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = DecisionTreeRegressor(min_samples_split=10, random_state=42)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_result_dcr = []\n",
    "for i, row in enumerate(X_predict):\n",
    "    tmp = regressor.predict(row.reshape(1, 4))\n",
    "    y_result_dcr.append([tmp, to_predict.iloc[i].at['danceability']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_array = np.array(y_result)\n",
    "ind = np.argsort(-acc_array[:,0]) # Reverse order\n",
    "sorted = acc_array[ind]\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(sorted[:,0] , label = 'Real values')\n",
    "plt.plot(sorted[:,1], label =  'Prediction')\n",
    "plt.title('Test Accuracy')\n",
    "plt.ylabel('Values')\n",
    "plt.xlabel('Datapoints')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bi-variate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify[spotify['track_name'] == 'YMCA - Original Version 1978']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "limiting tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=spotify, x='danceability', y='valence')\n",
    "sns.set(rc={'figure.figsize':(10,10)})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=spotify, x='danceability', y='loudness')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=spotify, x='danceability', y='acousticness')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a14426722b25adc768cfea782f621c901ff82b6a9f568e699338819587caab5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
